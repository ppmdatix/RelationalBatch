{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eeced768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_model import create_model\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from learn_that import apply_model\n",
    "\n",
    "from copy import deepcopy as deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6a1780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "588ab485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 0.1- np.random.random((datasize,10)) \n",
    "\n",
    "Y = np.random.random(datasize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc6fe84",
   "metadata": {},
   "source": [
    "This is md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb2898df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model, optimizer, loss_fn = create_model(X, optim=\"sparse_adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fedbddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = list(model.named_parameters())\n",
    "t = parameters[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "243b7b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('blocks.0.linear.weight',\n",
       " Parameter containing:\n",
       " tensor([[-0.0024,  0.1696, -0.2603, -0.2327, -0.1218,  0.0848, -0.0063,  0.2507,\n",
       "          -0.0281,  0.0837],\n",
       "         [-0.0956, -0.0622, -0.3021, -0.2094, -0.1304,  0.0117,  0.1250,  0.1897,\n",
       "          -0.2144, -0.1377],\n",
       "         [ 0.1149,  0.2626, -0.0651,  0.2366, -0.0510,  0.0335,  0.2863, -0.2934,\n",
       "          -0.1991, -0.0801],\n",
       "         [-0.1233,  0.2732, -0.2050, -0.1456, -0.2209, -0.2962, -0.1846,  0.2718,\n",
       "           0.1411,  0.1533]], requires_grad=True))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea9dbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = torch.tensor(X)\n",
    "tx = torch.max(tx, torch.zeros_like(tx))\n",
    "# tx = tx.to_sparse()\n",
    "ty = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "764818a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = tx.type(torch.FloatTensor), ty.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7a7bfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(apply_model(tx, model=model).squeeze(1), ty)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "928ae848",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    p = p.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3feefe84",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "SparseAdam does not support dense gradients, please consider Adam instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [86]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rBatch\\lib\\site-packages\\torch\\autograd\\grad_mode.py:26\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[1;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rBatch\\lib\\site-packages\\torch\\optim\\sparse_adam.py:70\u001b[0m, in \u001b[0;36mSparseAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     68\u001b[0m grad \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mis_sparse:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseAdam does not support dense gradients, please consider Adam instead\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     72\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[p]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# State initialization\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: SparseAdam does not support dense gradients, please consider Adam instead"
     ]
    }
   ],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7da03de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('blocks.0.linear.weight',\n",
       " Parameter containing:\n",
       " tensor([[-0.0024,  0.1696, -0.2603, -0.2327, -0.1218,  0.0848, -0.0063,  0.2507,\n",
       "          -0.0281,  0.0837],\n",
       "         [-0.0956, -0.0622, -0.3021, -0.2094, -0.1304,  0.0117,  0.1250,  0.1897,\n",
       "          -0.2144, -0.1377],\n",
       "         [ 0.1149,  0.2626, -0.0651,  0.2366, -0.0510,  0.0335,  0.2863, -0.2934,\n",
       "          -0.1991, -0.0801],\n",
       "         [-0.1233,  0.2732, -0.2050, -0.1456, -0.2209, -0.2962, -0.1846,  0.2718,\n",
       "           0.1411,  0.1533]], requires_grad=True))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = list(model.named_parameters())\n",
    "t = parameters[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3699fddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0, 2, 2, 2, 2],\n",
       "                       [1, 4, 6, 1, 4, 6, 8]]),\n",
       "       values=tensor([-0.0012, -0.0019, -0.0020,  0.0012,  0.0019,  0.0020,\n",
       "                       0.0021]),\n",
       "       size=(4, 10), nnz=7, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1].grad.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae5f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  nn.Conv2d(5, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test.named_parameters())[0][1].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ce786",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = t[1]\n",
    "y = torch.zeros_like(x)\n",
    "torch.where(grad != 0, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99efb7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48c002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
